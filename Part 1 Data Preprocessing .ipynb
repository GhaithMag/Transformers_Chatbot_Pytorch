{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9bb458",
   "metadata": {},
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torch.utils.data\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9c611",
   "metadata": {},
   "source": [
    "#### Steps for Data Cleaning:\n",
    "1. Load the raw text of movie conversations and lines.\n",
    "2. Create a dictionary to map each line's ID to its text.\n",
    "3. Remove punctuations and convert text to lowercase.\n",
    "4. Create question-answer pairs.\n",
    "5. Count word frequencies and build a vocabulary.\n",
    "6. Encode the questions and answers using the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b60e2",
   "metadata": {},
   "source": [
    "#### Function for preprocessing data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_conversations_path = 'movie_conversations.txt'\n",
    "movie_lines_path= 'movie_lines.txt'\n",
    "max_sequence_length= 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df13bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text corpus from a file and return as a list of lines\n",
    "def load_corpus(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "# Create a dictionary mapping line IDs to their corresponding text\n",
    "def create_line_dict(lines):\n",
    "    line_dict = {}\n",
    "    for line in lines:\n",
    "        parts = line.split(\" +++$+++ \")\n",
    "        line_dict[parts[0]] = parts[-1]\n",
    "    return line_dict\n",
    "\n",
    "# Remove punctuations and convert text to lowercase\n",
    "def clean_text(text):\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    return ''.join(char.lower() for char in text if char not in punctuations)\n",
    "\n",
    "# Create question-answer pairs from conversations\n",
    "def create_qa_pairs(conversations, line_dict):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        ids = eval(conversation.split(\" +++$+++ \")[-1])\n",
    "        for i in range(len(ids) - 1):\n",
    "            question = clean_text(line_dict[ids[i]].strip())\n",
    "            answer = clean_text(line_dict[ids[i+1]].strip())\n",
    "            qa_pairs.append([question.split()[:max_sequence_length], answer.split()[:max_sequence_length]])\n",
    "    return qa_pairs\n",
    "\n",
    "# Encode reply text to integer values\n",
    "def encode_reply(words, word_map, max_length=max_len):\n",
    "    encoded = [word_map['<start>']]\n",
    "    encoded += [word_map.get(word, word_map['<unk>']) for word in words]\n",
    "    encoded.append(word_map['<end>'])\n",
    "    padding_needed = max_length - len(encoded)\n",
    "    encoded.extend([word_map['<pad>']] * padding_needed)\n",
    "    return encoded\n",
    "\n",
    "# Encode question text to integer values\n",
    "def encode_question(words, word_map, max_length=max_len):\n",
    "    encoded = [word_map.get(word, word_map['<unk>']) for word in words]\n",
    "    padding_needed = max_length - len(encoded)\n",
    "    encoded.extend([word_map['<pad>']] * padding_needed)\n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73a547",
   "metadata": {},
   "source": [
    "#### Data Cleaning Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = load_corpus(movie_conversations_path)\n",
    "lines = load_corpus(movie_lines_path)\n",
    "\n",
    "# Create line dictionary\n",
    "line_dict = create_line_dict(lines)\n",
    "\n",
    "# Create question-answer pairs\n",
    "qa_pairs = create_qa_pairs(conversations, line_dict)\n",
    "\n",
    "# Count word frequencies and build vocabulary\n",
    "word_frequency = Counter()\n",
    "for pair in qa_pairs:\n",
    "    word_frequency.update(pair[0])\n",
    "    word_frequency.update(pair[1])\n",
    "\n",
    "min_frequency = 5\n",
    "vocab = [word for word, freq in word_frequency.items() if freq > min_frequency]\n",
    "word_map = {word: idx + 1 for idx, word in enumerate(vocab)}\n",
    "word_map.update({'<unk>': len(word_map) + 1, '<start>': len(word_map) + 2, '<end>': len(word_map) + 3, '<pad>': 0})\n",
    "\n",
    "# Save word map\n",
    "with open('WORDMAP_corpus.json', 'w') as json_file:\n",
    "    json.dump(word_map, json_file)\n",
    "\n",
    "\n",
    "    # Loop through each question-answer pair in the original 'pairs' list\n",
    "pairs_encoded = []\n",
    "for pair in qa_pairs:\n",
    "    # Encode the question part of the pair using the 'encode_question' function\n",
    "    qus = encode_question(pair[0], word_map)\n",
    "    \n",
    "    # Encode the answer part of the pair using the 'encode_reply' function\n",
    "    ans = encode_reply(pair[1], word_map)\n",
    "    \n",
    "    # Append the encoded question and answer as a pair to 'pairs_encoded' list\n",
    "    pairs_encoded.append([qus, ans])\n",
    "\n",
    "# Save the encoded pairs to a JSON file for future use\n",
    "with open('pairs_encoded.json', 'w') as p:\n",
    "    json.dump(pairs_encoded, p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
